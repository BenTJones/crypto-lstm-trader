{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20e69a13",
   "metadata": {},
   "source": [
    "Testing Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1b68bd",
   "metadata": {},
   "source": [
    "This notebook will be used to import and run the programmed scripts to keep outputs contained into just this file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e2bed6",
   "metadata": {},
   "source": [
    "0. Initial import of modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203ea872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "print(os.getcwd())\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250c5475",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.fetch_binance import fetch_binance\n",
    "from preprocessing.prep_data import feature_creation, z_score_norm, window_creation, train_val_test_split, target_def_knext, make_label_k_epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3275036c",
   "metadata": {},
   "source": [
    "1. Obtaining the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85d8aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fetch_binance(\n",
    "    exchange_ticker='BTC/USDT',\n",
    "    start_date='2017-01-01T00:00:00Z',\n",
    "    timeframe='1h',\n",
    "    cache_path=('./data/usd_btc_binance.csv'),\n",
    "    max_age_hrs=3\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812e3598",
   "metadata": {},
   "source": [
    "2. Normalisation and Window Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0f85f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#df = target_def_knext(df,4)\n",
    "labeled_df = make_label_k_epsilon(df,12,0.7,0.7,True)\n",
    "mod_df = feature_creation(labeled_df)\n",
    "\n",
    "norm_df = z_score_norm(mod_df, train_frac= 0.7)\n",
    "\n",
    "x, y = window_creation(norm_df, window_size=48)\n",
    "\n",
    "x.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90dd6fa",
   "metadata": {},
   "source": [
    "3. Splitting data into test, validation and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23354e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_val, y_val,x_test, y_test = train_val_test_split(x, y)\n",
    "x_lengths = map(len,[x_train,x_val,x_test])\n",
    "y_lengths = map(len,[y_train,y_val,y_test])\n",
    "print(list(x_lengths))\n",
    "print(list(y_lengths)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9ce345",
   "metadata": {},
   "source": [
    "4. Wrap the data in custom datasets so torch dataloaders can be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7784cda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from datasets.sequence_dataset import SequenceDataset\n",
    "\n",
    "batch_size= 64\n",
    "train_loader= DataLoader(SequenceDataset(x_train,y_train),batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(SequenceDataset(x_val,y_val), batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(SequenceDataset(x_test,y_test),batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45c314f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_split(loader):\n",
    "    n = 0; pos = 0\n",
    "    for _, y in loader:\n",
    "        y = y\n",
    "        n += y.numel()\n",
    "        pos += y.sum().item()\n",
    "    p = pos / n\n",
    "    print(f\"Samples={n}, Positives={pos} ({p:.3f})\")\n",
    "    return p\n",
    "\n",
    "print(\"Train split:\"); p_train = inspect_split(train_loader)\n",
    "print(\"Val split:\");   p_val   = inspect_split(val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf49b48d",
   "metadata": {},
   "source": [
    "5. Model set up and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1807ddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.lstm import LSTMClassifier\n",
    "from train.train_model import fit , positive_weight, select_threshold_constrained, threshold_free_metrics\n",
    "\n",
    "input_size = x_train.size(-1)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LSTMClassifier(input_size=input_size,hidden_size=128,num_layers= 2, dropout= 0.1)\n",
    "pos_weight = positive_weight(y_train,device)\n",
    "model,t_star,history = fit(\n",
    "        model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        epochs=40,\n",
    "        lr=1e-3,              \n",
    "        device=device,\n",
    "        save_path=\"models/best.pt\",\n",
    "        patience= 7,            # optional early stopping\n",
    "        pos_weight= None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796c8c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, average_precision_score, confusion_matrix\n",
    "\n",
    "model.eval()\n",
    "probs_test, ys_test = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        # probs in [0,1]\n",
    "        probs_test.append(model(xb.to(device)).sigmoid().cpu().numpy())\n",
    "        ys_test.append(yb.numpy())\n",
    "\n",
    "probs_test = np.concatenate(probs_test).ravel()\n",
    "ys_test   = np.concatenate(ys_test).ravel()\n",
    "\n",
    "# Lock the val-chosen threshold for test\n",
    "yhat_test = (probs_test >= t_star).astype(float)\n",
    "\n",
    "print(f\"t* (chosen on validation): {t_star:.3f}\")\n",
    "print(\"TEST ROC-AUC:\", roc_auc_score(ys_test, probs_test))\n",
    "print(\"TEST PR-AUC:\",  average_precision_score(ys_test, probs_test))\n",
    "print(\"TEST F1:\",      f1_score(ys_test, yhat_test))\n",
    "print(\"TEST Precision:\", precision_score(ys_test, yhat_test))\n",
    "print(\"TEST Recall:\",    recall_score(ys_test, yhat_test))\n",
    "print(\"TEST Confusion Matrix:\\n\", confusion_matrix(ys_test, yhat_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2852f593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, average_precision_score\n",
    "\n",
    "# Baseline: predict all positives\n",
    "yhat_allpos = np.ones_like(ys_test)\n",
    "\n",
    "print(\"BASELINE (all positive)\")\n",
    "print(\"F1:\", f1_score(ys_test, yhat_allpos))\n",
    "print(\"Precision:\", precision_score(ys_test, yhat_allpos))\n",
    "print(\"Recall:\", recall_score(ys_test, yhat_allpos))\n",
    "print(\"ROC-AUC:\", 0.5)\n",
    "print(\"PR-AUC (â‰ˆ base rate):\", ys_test.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2325a9c4",
   "metadata": {},
   "source": [
    "Beginning of HyperTuning - Testing to see the model can learn and if changing things elsewhere (data/features/splitting/optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed97dc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tiny_overfit(model, train_ds, steps=500, k=64, lr=3e-3):\n",
    "    from torch.optim import AdamW\n",
    "    from torch.nn.utils import clip_grad_norm_\n",
    "    import random, torch, torch.nn as nn\n",
    "    idx = torch.randperm(len(train_ds))[:k]\n",
    "    X_small = []; y_small = []\n",
    "    for i in idx:\n",
    "        X, y = train_ds[i]\n",
    "        X_small.append(X.unsqueeze(0)); y_small.append(y)\n",
    "    X_small = torch.cat(X_small, dim=0)  # [k, T, F]\n",
    "    y_small = torch.tensor(y_small).float()  # [k]\n",
    "\n",
    "    model.train()\n",
    "    opt = AdamW(model.parameters(), lr=lr)\n",
    "    crit = torch.nn.BCEWithLogitsLoss()\n",
    "    for t in range(steps):\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        logits = model(X_small.to(device))\n",
    "        loss = crit(logits.squeeze(-1), y_small.to(device))\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(model.parameters(), 1.0)\n",
    "        opt.step()\n",
    "        if (t+1) % 50 == 0:\n",
    "            with torch.no_grad():\n",
    "                p = (logits.squeeze(-1).sigmoid()>0.5).float()\n",
    "                acc = (p.cpu()==y_small).float().mean().item()\n",
    "            print(f'{t+1:04d} | loss {loss.item():.4f} | acc {acc:.3f}')\n",
    "\n",
    "tiny_overfit(\n",
    "    model=model,\n",
    "    train_ds=SequenceDataset(x_train,y_train),\n",
    "    steps=500,   # updates, not epochs\n",
    "    k=64,        # number of samples to memorize\n",
    "    lr=3e-3      # slightly higher LR for speed\n",
    ")\n",
    "\n",
    "#FROM THIS CELLS OUTPUT OF AN ACCURACY OF 1+ CONSISTENLY AND LOSS OF 0  SO MODEL CAN DEFINETLY LEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b55485",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Test a regression model on data\n",
    "\n",
    "def make_tabular_last(norm_df, window_size=48):\n",
    "    feats = norm_df.drop(columns=['label'])\n",
    "    y = norm_df['label'].to_numpy().astype(int)\n",
    "    Xrows, yrows = [], []\n",
    "    for i in range(len(norm_df) - window_size + 1):\n",
    "        j = i + window_size - 1\n",
    "        Xrows.append(feats.iloc[j].to_numpy())\n",
    "        yrows.append(y[j])\n",
    "    X = np.vstack(Xrows); y = np.array(yrows)\n",
    "    return X, y\n",
    "\n",
    "def chrono_split(X, y, train_frac=0.7, val_frac=0.15):\n",
    "    n = len(y)\n",
    "    i_tr = int(n * train_frac)\n",
    "    i_v  = int(n * (train_frac + val_frac))\n",
    "    return (X[:i_tr], y[:i_tr]), (X[i_tr:i_v], y[i_tr:i_v]), (X[i_v:], y[i_v:])\n",
    "\n",
    "def eval_with_constraints(probs, y, min_pos_rate=0.05, max_pos_rate=0.95, min_precision=None):\n",
    "    roc, pr = threshold_free_metrics(probs, y)\n",
    "    tinfo = select_threshold_constrained(probs, y, min_pos_rate, max_pos_rate, min_precision)\n",
    "    if tinfo[\"f1\"] < 0:\n",
    "        return {\"roc\": roc, \"pr\": pr, \"t\": None, \"f1\": None, \"prec\": None, \"rec\": None, \"pos_rate\": None}\n",
    "    yhat = (probs >= tinfo[\"t\"])\n",
    "    return {\n",
    "        \"roc\": roc, \"pr\": pr, \"t\": tinfo[\"t\"], \"f1\": tinfo[\"f1\"],\n",
    "        \"prec\": precision_score(y, yhat, zero_division=0),\n",
    "        \"rec\":  recall_score(y, yhat, zero_division=0),\n",
    "        \"pos_rate\": float(yhat.mean())\n",
    "    }\n",
    "\n",
    "def logistic_baseline(norm_df, window_size=48, C=1.0, max_iter=2000):\n",
    "    X, y = make_tabular_last(norm_df, window_size)\n",
    "    (Xtr, ytr), (Xv, yv), (Xte, yte) = chrono_split(X, y, 0.7, 0.15)\n",
    "    cls_wt = \"balanced\" if (ytr.mean() < 0.35 or ytr.mean() > 0.65) else None\n",
    "    lr = LogisticRegression(C=C, max_iter=max_iter, solver=\"lbfgs\", class_weight=cls_wt)\n",
    "    lr.fit(Xtr, ytr)\n",
    "\n",
    "    pv = lr.predict_proba(Xv)[:,1]\n",
    "    min_prec = max(0.55, float(yv.mean()))\n",
    "    val_metrics = eval_with_constraints(pv, yv, 0.05, 0.95, min_prec)\n",
    "\n",
    "    pt = lr.predict_proba(Xte)[:,1]\n",
    "    if val_metrics[\"t\"] is not None:\n",
    "        yhat_t = (pt >= val_metrics[\"t\"])\n",
    "        test_metrics = {\n",
    "            \"roc\": roc_auc_score(yte, pt),\n",
    "            \"pr\":  average_precision_score(yte, pt),\n",
    "            \"f1\":  f1_score(yte, yhat_t, zero_division=0),\n",
    "            \"prec\": precision_score(yte, yhat_t, zero_division=0),\n",
    "            \"rec\":  recall_score(yte, yhat_t, zero_division=0),\n",
    "            \"pos_rate\": float(yhat_t.mean()),\n",
    "            \"t\": val_metrics[\"t\"],\n",
    "        }\n",
    "    else:\n",
    "        test_metrics = {\"roc\": roc_auc_score(yte, pt), \"pr\": average_precision_score(yte, pt),\n",
    "                        \"f1\": None, \"prec\": None, \"rec\": None, \"pos_rate\": None, \"t\": None}\n",
    "    return val_metrics, test_metrics\n",
    "\n",
    "val_m, test_m = logistic_baseline(norm_df, window_size=48)\n",
    "print(\"LogReg VAL:\", val_m)\n",
    "print(\"LogReg TEST:\", test_m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de113e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_df = feature_creation(df) \n",
    "\n",
    "#Try a few labels: k in {6,8,12}, epsilon= 60% or 70% \n",
    "tests = []\n",
    "for k in (6, 8, 12):\n",
    "    for q in (0.60, 0.70):\n",
    "        labeled = make_label_k_epsilon(feat_df, k=k, eps_quantile=q, train_frac=0.7, use_log_returns=True)\n",
    "        norm = z_score_norm(labeled, train_frac=0.7)\n",
    "\n",
    "        # Find baseline results for comapring\n",
    "        val_m, test_m = logistic_baseline(norm, window_size=48)  \n",
    "        tests.append((k, q, val_m[\"pr\"], val_m[\"roc\"], test_m[\"pr\"], test_m[\"roc\"]))\n",
    "\n",
    "\n",
    "print(\"k  eps_q   VAL_PR   VAL_ROC   TEST_PR  TEST_ROC\")\n",
    "for k, q, vpr, vroc, tpr, troc in tests:\n",
    "    print(f\"{k:<2} {q:<5}  {vpr:.3f}    {vroc:.3f}     {tpr:.3f}    {troc:.3f}\")\n",
    "\n",
    "\n",
    "best = max(tests, key=lambda x: x[2])\n",
    "print(\"\\nBEST (by VAL_PR): k=%d, eps_q=%.2f  VAL_PR=%.3f  VAL_ROC=%.3f\" % (best[0], best[1], best[2], best[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963bc51a",
   "metadata": {},
   "source": [
    "6. Testing the model on test data set and comparing outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fca76f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
